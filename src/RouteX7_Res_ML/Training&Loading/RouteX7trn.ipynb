{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNx+YCdJ6yrh++FV2PnB1nF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install latest torch/vision (Colab usually has them)\n","!pip -q install --upgrade torch torchvision torchaudio"],"metadata":{"id":"X_F4MaY40pOZ","executionInfo":{"status":"ok","timestamp":1757293001427,"user_tz":-540,"elapsed":8538,"user":{"displayName":"Amartuvshin Boldbaatar","userId":"05685717451559994189"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"id":"TCDkJG3Sy_X0","executionInfo":{"status":"ok","timestamp":1757292992894,"user_tz":-540,"elapsed":34529,"user":{"displayName":"Amartuvshin Boldbaatar","userId":"05685717451559994189"}},"outputId":"a6d1a0d7-7e8f-44e9-9a43-60c5b775eb3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ‘‰ Upload your kaggle.json (create from https://www.kaggle.com/settings/account)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d72038cd-28b6-47bf-ba5c-24e9bd22538e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d72038cd-28b6-47bf-ba5c-24e9bd22538e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/tallwinkingstan/road-traversing-knowledge-rtk-dataset?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 723M/723M [00:09<00:00, 79.0MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/tallwinkingstan/road-traversing-knowledge-rtk-dataset/versions/1\n"]}],"source":["# Install kaggle and download the dataset\n","!pip -q install kaggle kagglehub\n","\n","from google.colab import files\n","print(\"ðŸ‘‰ Upload your kaggle.json (create from https://www.kaggle.com/settings/account)\")\n","files.upload()  # select kaggle.json\n","\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","import kagglehub\n","rtk_path = kagglehub.dataset_download(\"tallwinkingstan/road-traversing-knowledge-rtk-dataset\")\n","print(\"Path to dataset files:\", rtk_path)\n"]},{"cell_type":"code","source":["import os, shutil, random\n","from pathlib import Path\n","random.seed(42)\n","\n","# Try to locate the root RTK directory (case/typo tolerant)\n","candidates = [\n","    \"RTK_Dataset\", \"RTK_dataset\", \"RTK_dataset/\",\n","    \"RTK_Dataset/\", \"RTK_dataset/RTK_Dataset\", \"RTK_Dataset/RTK_dataset\"\n","]\n","DATASET_DIR = None\n","for c in candidates:\n","    p = os.path.join(rtk_path, c)\n","    if os.path.isdir(p):\n","        DATASET_DIR = p\n","        break\n","\n","# If none of the above worked, try directly scanning one level down\n","if DATASET_DIR is None:\n","    for name in os.listdir(rtk_path):\n","        full = os.path.join(rtk_path, name)\n","        if os.path.isdir(full) and \"rtk\" in name.lower():\n","            DATASET_DIR = full\n","            break\n","\n","print(\"Detected DATASET_DIR:\", DATASET_DIR)\n","assert DATASET_DIR and os.path.isdir(DATASET_DIR), \"Could not find RTK dataset folder. Inspect rtk_path printed above.\"\n","\n","# Build a tolerant mapping for source â†’ target class\n","def first_existing(*parts):\n","    \"\"\"Return the first subpath that actually exists inside DATASET_DIR.\"\"\"\n","    for rel in parts:\n","        full = os.path.join(DATASET_DIR, rel)\n","        if os.path.isdir(full):\n","            return rel\n","    return None\n","\n","label_map = {}\n","\n","# Asphalt\n","label_map[first_existing(\"asphalt/asphaltGood\", \"asphalt/Good\", \"asphalt/good\")] = \"asphalt_good\"\n","label_map[first_existing(\"asphalt/asphaltRegular\", \"asphalt/Regular\", \"asphalt/regular\")] = \"asphalt_regular\"\n","label_map[first_existing(\"asphalt/asphaltBad\", \"asphalt/Bad\", \"asphalt/bad\")] = \"asphalt_bad\"\n","\n","# Paved\n","label_map[first_existing(\"paved/pavedRegular\", \"paved/Regular\", \"paved/regular\")] = \"paved_regular\"\n","label_map[first_existing(\"paved/pavedBad\", \"paved/Bad\", \"paved/bad\")] = \"paved_bad\"\n","\n","# Unpaved (handle common 'upaved' typo)\n","label_map[first_existing(\"unpaved/unpavedRegular\", \"upaved/unpavedRegular\", \"unpaved/Regular\", \"upaved/Regular\", \"unpaved/regular\")] = \"unpaved_regular\"\n","label_map[first_existing(\"unpaved/unpavedBad\", \"upaved/unpavedBad\", \"unpaved/Bad\", \"upaved/Bad\", \"unpaved/bad\")] = \"unpaved_bad\"\n","\n","# Clean None keys if any didn't exist\n","label_map = {k:v for k,v in label_map.items() if k is not None}\n","print(\"Resolved source â†’ target classes:\")\n","for k,v in label_map.items():\n","    print(\" \", k, \"â†’\", v)\n","\n","expected_targets = {\n","    \"asphalt_good\",\"asphalt_regular\",\"asphalt_bad\",\n","    \"paved_regular\",\"paved_bad\",\n","    \"unpaved_regular\",\"unpaved_bad\"\n","}\n","assert set(label_map.values()) == expected_targets, f\"Missing classes. Got {set(label_map.values())}\"\n","\n","# Output dir\n","OUTPUT_DIR = \"/content/prepared_dataset\"\n","for split in [\"train\", \"val\", \"test\"]:\n","    for cls in expected_targets:\n","        Path(f\"{OUTPUT_DIR}/{split}/{cls}\").mkdir(parents=True, exist_ok=True)\n","\n","train_ratio, val_ratio, test_ratio = 0.70, 0.15, 0.15\n","\n","def split_and_copy(src_dir, dst_label):\n","    files = [f for f in os.listdir(src_dir) if not f.startswith(\".\")]\n","    random.shuffle(files)\n","    n = len(files)\n","    n_train = int(n*train_ratio)\n","    n_val   = int(n*val_ratio)\n","    splits = {\n","        \"train\": files[:n_train],\n","        \"val\":   files[n_train:n_train+n_val],\n","        \"test\":  files[n_train+n_val:]\n","    }\n","    for split, split_files in splits.items():\n","        for f in split_files:\n","            src = os.path.join(src_dir, f)\n","            dst = os.path.join(OUTPUT_DIR, split, dst_label, f)\n","            if os.path.isfile(src):\n","                shutil.copy(src, dst)\n","\n","# Do the split\n","for rel_src, tgt in label_map.items():\n","    split_and_copy(os.path.join(DATASET_DIR, rel_src), tgt)\n","\n","print(\"âœ… Prepared at:\", OUTPUT_DIR)\n","\n","# Show quick counts\n","from collections import Counter\n","def count_images(root):\n","    counts = {}\n","    for split in [\"train\",\"val\",\"test\"]:\n","        c = Counter()\n","        for cls in expected_targets:\n","            d = os.path.join(root, split, cls)\n","            c[cls] = len([x for x in os.listdir(d) if not x.startswith(\".\")])\n","        counts[split] = dict(c)\n","    return counts\n","\n","counts = count_images(OUTPUT_DIR)\n","counts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnbyKiBb0xfQ","executionInfo":{"status":"ok","timestamp":1757293026949,"user_tz":-540,"elapsed":2969,"user":{"displayName":"Amartuvshin Boldbaatar","userId":"05685717451559994189"}},"outputId":"e72393f0-d117-4ddd-8222-ed9804e235e9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected DATASET_DIR: /root/.cache/kagglehub/datasets/tallwinkingstan/road-traversing-knowledge-rtk-dataset/versions/1/RTK_Dataset\n","Resolved source â†’ target classes:\n","  asphalt/asphaltGood â†’ asphalt_good\n","  asphalt/asphaltRegular â†’ asphalt_regular\n","  asphalt/asphaltBad â†’ asphalt_bad\n","  paved/pavedRegular â†’ paved_regular\n","  paved/pavedBad â†’ paved_bad\n","  upaved/unpavedRegular â†’ unpaved_regular\n","  upaved/unpavedBad â†’ unpaved_bad\n","âœ… Prepared at: /content/prepared_dataset\n"]},{"output_type":"execute_result","data":{"text/plain":["{'train': {'unpaved_regular': 557,\n","  'paved_regular': 226,\n","  'paved_bad': 86,\n","  'asphalt_bad': 324,\n","  'unpaved_bad': 415,\n","  'asphalt_regular': 587,\n","  'asphalt_good': 1384},\n"," 'val': {'unpaved_regular': 119,\n","  'paved_regular': 48,\n","  'paved_bad': 18,\n","  'asphalt_bad': 69,\n","  'unpaved_bad': 88,\n","  'asphalt_regular': 125,\n","  'asphalt_good': 296},\n"," 'test': {'unpaved_regular': 120,\n","  'paved_regular': 50,\n","  'paved_bad': 20,\n","  'asphalt_bad': 71,\n","  'unpaved_bad': 90,\n","  'asphalt_regular': 127,\n","  'asphalt_good': 298}}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import os, time, shutil\n","CKPT_PATH = \"/content/driveA/MyDrive/rtk_resnet/resnet18_rtk_best.pth\"\n","TS_PATH   = \"/content/driveA/MyDrive/rtk_resnet/resnet18_rtk_scripted.pt\"\n","LABELS_PATH = \"/content/driveA/MyDrive/rtk_resnet/class_names.json\"\n","\n","stamp = time.strftime(\"%Y%m%d-%H%M%S\")\n","backup_dir = f\"/content/driveA/MyDrive/rtk_resnet/_backup_{stamp}\"\n","os.makedirs(backup_dir, exist_ok=True)\n","for p in [CKPT_PATH, TS_PATH, LABELS_PATH]:\n","    if os.path.isfile(p):\n","        shutil.copy2(p, backup_dir)\n","backup_dir\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"2tbHRgRn3Rj5","executionInfo":{"status":"ok","timestamp":1757293854409,"user_tz":-540,"elapsed":7941,"user":{"displayName":"Amartuvshin Boldbaatar","userId":"05685717451559994189"}},"outputId":"3342b0d2-2085-415e-f9fe-4e01769d162a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/driveA/MyDrive/rtk_resnet/_backup_20250908-010957'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from google.colab import drive; drive.mount('/content/driveA')\n","CKPT_PATH = \"/content/driveA/MyDrive/rtk_resnet/resnet18_rtk_best.pth\"      # overwrite here\n","TS_PATH   = \"/content/driveA/MyDrive/rtk_resnet/resnet18_rtk_scripted.pt\"   # overwrite here\n","LABELS_PATH = \"/content/driveA/MyDrive/rtk_resnet/class_names.json\"         # MUST keep same order\n","\n","DATA_DIR = \"/content/prepared_dataset\"   # your updated dataset (train/val/â€¦)\n","IMG_SIZE = 224\n","BATCH_SIZE = 32\n","EPOCHS_MORE = 10\n","LR = 5e-5            # lower LR for resume\n","WEIGHT_DECAY = 1e-4\n"],"metadata":{"id":"utKsigwu3YB4","executionInfo":{"status":"ok","timestamp":1757293826192,"user_tz":-540,"elapsed":14,"user":{"displayName":"Amartuvshin Boldbaatar","userId":"05685717451559994189"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!pip -q install --upgrade torch torchvision pillow\n"],"metadata":{"id":"w7PLklQR4Edf","executionInfo":{"status":"ok","timestamp":1757293869147,"user_tz":-540,"elapsed":6882,"user":{"displayName":"Amartuvshin Boldbaatar","userId":"05685717451559994189"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import os, json, numpy as np\n","import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","train_tf = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.RandomHorizontalFlip(0.5),\n","    transforms.RandomApply([transforms.ColorJitter(0.3,0.3,0.2,0.05)], p=0.5),\n","    transforms.RandomAffine(10, translate=(0.05,0.05), scale=(0.95,1.05)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n","])\n","eval_tf = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n","])\n","\n","train_ds = datasets.ImageFolder(os.path.join(DATA_DIR,\"train\"), transform=train_tf)\n","val_ds   = datasets.ImageFolder(os.path.join(DATA_DIR,\"val\"),   transform=eval_tf)\n","\n","# load saved class order and assert same\n","with open(LABELS_PATH,\"r\") as f:\n","    saved_classes = json.load(f)\n","current_classes = sorted(train_ds.class_to_idx.keys())\n","assert saved_classes == current_classes, \"Class names/order changed â€“ keep the same 7 classes/order.\"\n","\n","# weighted sampler for imbalance\n","labels = [y for _,y in train_ds.samples]\n","counts = np.bincount(labels, minlength=len(saved_classes)).astype(np.float32)\n","class_weights = 1.0 / np.maximum(counts, 1)\n","sample_w = [class_weights[y] for y in labels]\n","sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n","val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n"],"metadata":{"id":"pv0PdBSx4GmJ","executionInfo":{"status":"ok","timestamp":1757293902846,"user_tz":-540,"elapsed":20206,"user":{"displayName":"Amartuvshin Boldbaatar","userId":"05685717451559994189"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn, torch.optim as optim\n","from torchvision import models\n","from time import time\n","\n","# load checkpoint\n","ckpt = torch.load(CKPT_PATH, map_location=device)\n","best_val = ckpt.get(\"best_val_acc\", 0.0)\n","\n","# build model and load weights\n","model = models.resnet18(weights=None)\n","model.fc = nn.Linear(model.fc.in_features, len(saved_classes))\n","model.load_state_dict(ckpt[\"model_state\"])\n","model.to(device)\n","\n","# optimizer (resume if present, but force new LR)\n","optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n","if \"optimizer_state\" in ckpt:\n","    try:\n","        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n","        for g in optimizer.param_groups: g[\"lr\"] = LR\n","    except Exception:\n","        pass\n","\n","criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32, device=device))\n","scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n","\n","def run_epoch(loader, train=True):\n","    model.train(train)\n","    total, correct, loss_sum = 0, 0, 0.0\n","    for x,y in loader:\n","        x,y = x.to(device), y.to(device)\n","        if train:\n","            optimizer.zero_grad(set_to_none=True)\n","            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n","                out = model(x); loss = criterion(out,y)\n","            scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n","        else:\n","            with torch.no_grad():\n","                out = model(x); loss = criterion(out,y)\n","        loss_sum += loss.item()*x.size(0)\n","        correct  += (out.argmax(1)==y).sum().item()\n","        total    += x.size(0)\n","    return loss_sum/total, correct/total\n","\n","patience, bad = 5, 0\n","for e in range(1, EPOCHS_MORE+1):\n","    t0=time()\n","    tr_loss,tr_acc = run_epoch(train_loader, True)\n","    va_loss,va_acc = run_epoch(val_loader, False)\n","    print(f\"[+{e:02d}] train {tr_loss:.4f}/{tr_acc:.4f} | val {va_loss:.4f}/{va_acc:.4f}  ({time()-t0:.1f}s)\")\n","    if va_acc > best_val:\n","        best_val = va_acc; bad = 0\n","        torch.save({\n","            \"epoch\": ckpt.get(\"epoch\",0)+e,\n","            \"model_state\": model.state_dict(),\n","            \"optimizer_state\": optimizer.state_dict(),\n","            \"class_names\": saved_classes,\n","            \"best_val_acc\": best_val\n","        }, CKPT_PATH)  # <-- overwrite same checkpoint path\n","        print(\"  âœ” saved improved checkpoint (overwrote CKPT_PATH)\")\n","    else:\n","        bad += 1\n","        if bad >= patience:\n","            print(\"Early stopping.\"); break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1NMp4R2a4LRW","outputId":"db40e6f7-7982-4d3c-f3a7-871be07c9213"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3950050034.py:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n","/tmp/ipython-input-3950050034.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"]},{"output_type":"stream","name":"stdout","text":["[+01] train 0.0360/0.9835 | val 0.0449/0.9882  (1049.6s)\n","  âœ” saved improved checkpoint (overwrote CKPT_PATH)\n"]}]},{"cell_type":"code","source":["# Overwrite TorchScript file as well\n","dummy = torch.randn(1,3,IMG_SIZE,IMG_SIZE).to(device)\n","model.eval()\n","scripted = torch.jit.trace(model, dummy)\n","scripted.save(TS_PATH)   # <-- overwrite same TorchScript path\n","print(\"Overwrote TorchScript:\", TS_PATH)\n"],"metadata":{"id":"DL710n264Y8V"},"execution_count":null,"outputs":[]}]}