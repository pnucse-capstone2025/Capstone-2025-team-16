{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation\n",
        "\n"
      ],
      "metadata": {
        "id": "eUfZtxhmxuZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "005NqH19dNPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4529c9a1-3451-4d7d-ca0d-8b8ade972d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "SAVE_DIR: /content/drive/MyDrive/model_comparison\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive to save models/checkpoints ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Where to save outputs\n",
        "SAVE_DIR = \"/content/drive/MyDrive/model_comparison\"\n",
        "import os\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "print(\"SAVE_DIR:\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install kaggle kagglehub\n",
        "\n",
        "from google.colab import files\n",
        "print(\"ðŸ‘‰ Upload your kaggle.json (create from https://www.kaggle.com/settings/account)\")\n",
        "files.upload()  # select kaggle.json\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "import kagglehub\n",
        "rtk_path = kagglehub.dataset_download(\"tallwinkingstan/road-traversing-knowledge-rtk-dataset\")\n",
        "print(\"Path to dataset files:\", rtk_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "Xv1FGHmcxp_d",
        "outputId": "9ab8a96f-15c3-4c8a-ffaf-59957622952a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ‘‰ Upload your kaggle.json (create from https://www.kaggle.com/settings/account)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b7f5bfd2-bde6-441f-aeb9-e9b20793176d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b7f5bfd2-bde6-441f-aeb9-e9b20793176d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/tallwinkingstan/road-traversing-knowledge-rtk-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 723M/723M [00:20<00:00, 36.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/tallwinkingstan/road-traversing-knowledge-rtk-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "from pathlib import Path\n",
        "random.seed(42)\n",
        "\n",
        "# Try to locate the root RTK directory (case/typo tolerant)\n",
        "candidates = [\n",
        "    \"RTK_Dataset\", \"RTK_dataset\", \"RTK_dataset/\",\n",
        "    \"RTK_Dataset/\", \"RTK_dataset/RTK_Dataset\", \"RTK_Dataset/RTK_dataset\"\n",
        "]\n",
        "DATASET_DIR = None\n",
        "for c in candidates:\n",
        "    p = os.path.join(rtk_path, c)\n",
        "    if os.path.isdir(p):\n",
        "        DATASET_DIR = p\n",
        "        break\n",
        "\n",
        "# If none of the above worked, try directly scanning one level down\n",
        "if DATASET_DIR is None:\n",
        "    for name in os.listdir(rtk_path):\n",
        "        full = os.path.join(rtk_path, name)\n",
        "        if os.path.isdir(full) and \"rtk\" in name.lower():\n",
        "            DATASET_DIR = full\n",
        "            break\n",
        "\n",
        "print(\"Detected DATASET_DIR:\", DATASET_DIR)\n",
        "assert DATASET_DIR and os.path.isdir(DATASET_DIR), \"Could not find RTK dataset folder. Inspect rtk_path printed above.\"\n",
        "\n",
        "# Build a tolerant mapping for source â†’ target class\n",
        "def first_existing(*parts):\n",
        "    \"\"\"Return the first subpath that actually exists inside DATASET_DIR.\"\"\"\n",
        "    for rel in parts:\n",
        "        full = os.path.join(DATASET_DIR, rel)\n",
        "        if os.path.isdir(full):\n",
        "            return rel\n",
        "    return None\n",
        "\n",
        "label_map = {}\n",
        "\n",
        "# Asphalt\n",
        "label_map[first_existing(\"asphalt/asphaltGood\", \"asphalt/Good\", \"asphalt/good\")] = \"asphalt_good\"\n",
        "label_map[first_existing(\"asphalt/asphaltRegular\", \"asphalt/Regular\", \"asphalt/regular\")] = \"asphalt_regular\"\n",
        "label_map[first_existing(\"asphalt/asphaltBad\", \"asphalt/Bad\", \"asphalt/bad\")] = \"asphalt_bad\"\n",
        "\n",
        "# Paved\n",
        "label_map[first_existing(\"paved/pavedRegular\", \"paved/Regular\", \"paved/regular\")] = \"paved_regular\"\n",
        "label_map[first_existing(\"paved/pavedBad\", \"paved/Bad\", \"paved/bad\")] = \"paved_bad\"\n",
        "\n",
        "# Unpaved (handle common 'upaved' typo)\n",
        "label_map[first_existing(\"unpaved/unpavedRegular\", \"upaved/unpavedRegular\", \"unpaved/Regular\", \"upaved/Regular\", \"unpaved/regular\")] = \"unpaved_regular\"\n",
        "label_map[first_existing(\"unpaved/unpavedBad\", \"upaved/unpavedBad\", \"unpaved/Bad\", \"upaved/Bad\", \"unpaved/bad\")] = \"unpaved_bad\"\n",
        "\n",
        "# Clean None keys if any didn't exist\n",
        "label_map = {k:v for k,v in label_map.items() if k is not None}\n",
        "print(\"Resolved source â†’ target classes:\")\n",
        "for k,v in label_map.items():\n",
        "    print(\" \", k, \"â†’\", v)\n",
        "\n",
        "expected_targets = {\n",
        "    \"asphalt_good\",\"asphalt_regular\",\"asphalt_bad\",\n",
        "    \"paved_regular\",\"paved_bad\",\n",
        "    \"unpaved_regular\",\"unpaved_bad\"\n",
        "}\n",
        "assert set(label_map.values()) == expected_targets, f\"Missing classes. Got {set(label_map.values())}\"\n",
        "\n",
        "# Output dir\n",
        "OUTPUT_DIR = \"/content/prepared_dataset\"\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for cls in expected_targets:\n",
        "        Path(f\"{OUTPUT_DIR}/{split}/{cls}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_ratio, val_ratio, test_ratio = 0.70, 0.15, 0.15\n",
        "\n",
        "def split_and_copy(src_dir, dst_label):\n",
        "    files = [f for f in os.listdir(src_dir) if not f.startswith(\".\")]\n",
        "    random.shuffle(files)\n",
        "    n = len(files)\n",
        "    n_train = int(n*train_ratio)\n",
        "    n_val   = int(n*val_ratio)\n",
        "    splits = {\n",
        "        \"train\": files[:n_train],\n",
        "        \"val\":   files[n_train:n_train+n_val],\n",
        "        \"test\":  files[n_train+n_val:]\n",
        "    }\n",
        "    for split, split_files in splits.items():\n",
        "        for f in split_files:\n",
        "            src = os.path.join(src_dir, f)\n",
        "            dst = os.path.join(OUTPUT_DIR, split, dst_label, f)\n",
        "            if os.path.isfile(src):\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "# Do the split\n",
        "for rel_src, tgt in label_map.items():\n",
        "    split_and_copy(os.path.join(DATASET_DIR, rel_src), tgt)\n",
        "\n",
        "print(\"âœ… Prepared at:\", OUTPUT_DIR)\n",
        "\n",
        "# Show quick counts\n",
        "from collections import Counter\n",
        "def count_images(root):\n",
        "    counts = {}\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        c = Counter()\n",
        "        for cls in expected_targets:\n",
        "            d = os.path.join(root, split, cls)\n",
        "            c[cls] = len([x for x in os.listdir(d) if not x.startswith(\".\")])\n",
        "        counts[split] = dict(c)\n",
        "    return counts\n",
        "\n",
        "counts = count_images(OUTPUT_DIR)\n",
        "counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifdnvsHTx3Qc",
        "outputId": "72393118-68a0-4cf5-fa94-2e19cf09c4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected DATASET_DIR: /root/.cache/kagglehub/datasets/tallwinkingstan/road-traversing-knowledge-rtk-dataset/versions/1/RTK_Dataset\n",
            "Resolved source â†’ target classes:\n",
            "  asphalt/asphaltGood â†’ asphalt_good\n",
            "  asphalt/asphaltRegular â†’ asphalt_regular\n",
            "  asphalt/asphaltBad â†’ asphalt_bad\n",
            "  paved/pavedRegular â†’ paved_regular\n",
            "  paved/pavedBad â†’ paved_bad\n",
            "  upaved/unpavedRegular â†’ unpaved_regular\n",
            "  upaved/unpavedBad â†’ unpaved_bad\n",
            "âœ… Prepared at: /content/prepared_dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'unpaved_regular': 557,\n",
              "  'asphalt_good': 1384,\n",
              "  'asphalt_regular': 587,\n",
              "  'paved_regular': 226,\n",
              "  'asphalt_bad': 324,\n",
              "  'unpaved_bad': 415,\n",
              "  'paved_bad': 86},\n",
              " 'val': {'unpaved_regular': 119,\n",
              "  'asphalt_good': 296,\n",
              "  'asphalt_regular': 125,\n",
              "  'paved_regular': 48,\n",
              "  'asphalt_bad': 69,\n",
              "  'unpaved_bad': 88,\n",
              "  'paved_bad': 18},\n",
              " 'test': {'unpaved_regular': 120,\n",
              "  'asphalt_good': 298,\n",
              "  'asphalt_regular': 127,\n",
              "  'paved_regular': 50,\n",
              "  'asphalt_bad': 71,\n",
              "  'unpaved_bad': 90,\n",
              "  'paved_bad': 20}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "from pathlib import Path\n",
        "\n",
        "SRC_ROOT = \"/content/prepared_dataset\"   # your current dataset\n",
        "DST_ROOT = \"/content/prepared_dataset_balanced\"  # new balanced copy\n",
        "CLASSES  = sorted(os.listdir(os.path.join(SRC_ROOT, \"train\")))\n",
        "random.seed(42)\n",
        "\n",
        "def balance_split(split):\n",
        "    per_class_files = {}\n",
        "    for cls in CLASSES:\n",
        "        d = os.path.join(SRC_ROOT, split, cls)\n",
        "        files = [os.path.join(d, f) for f in os.listdir(d) if not f.startswith(\".\")]\n",
        "        random.shuffle(files)\n",
        "        per_class_files[cls] = files\n",
        "\n",
        "    # target = min class count\n",
        "    min_n = min(len(v) for v in per_class_files.values())\n",
        "    print(f\"{split}: balancing to {min_n} per class\")\n",
        "\n",
        "    # make destination dirs\n",
        "    for cls in CLASSES:\n",
        "        Path(os.path.join(DST_ROOT, split, cls)).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # copy\n",
        "    for cls, files in per_class_files.items():\n",
        "        chosen = files[:min_n]\n",
        "        for src in chosen:\n",
        "            dst = os.path.join(DST_ROOT, split, cls, os.path.basename(src))\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "def count_split(root, split):\n",
        "    return {cls: len(os.listdir(os.path.join(root, split, cls))) for cls in CLASSES}\n",
        "\n",
        "# Balance train/val/test\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    balance_split(split)\n",
        "    print(split, count_split(DST_ROOT, split))\n",
        "\n",
        "print(\"âœ… Balanced dataset saved to:\", DST_ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwCTMuMdyCjv",
        "outputId": "b104fb40-403c-472d-e60c-f733249bf384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: balancing to 86 per class\n",
            "train {'asphalt_bad': 86, 'asphalt_good': 86, 'asphalt_regular': 86, 'paved_bad': 86, 'paved_regular': 86, 'unpaved_bad': 86, 'unpaved_regular': 86}\n",
            "val: balancing to 18 per class\n",
            "val {'asphalt_bad': 18, 'asphalt_good': 18, 'asphalt_regular': 18, 'paved_bad': 18, 'paved_regular': 18, 'unpaved_bad': 18, 'unpaved_regular': 18}\n",
            "test: balancing to 20 per class\n",
            "test {'asphalt_bad': 20, 'asphalt_good': 20, 'asphalt_regular': 20, 'paved_bad': 20, 'paved_regular': 20, 'unpaved_bad': 20, 'unpaved_regular': 20}\n",
            "âœ… Balanced dataset saved to: /content/prepared_dataset_balanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training & Comparison"
      ],
      "metadata": {
        "id": "r9S7ZiwCyGBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas scikit-learn\n",
        "\n",
        "import os, time, json, math, copy, random\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Z3pN1CNXy3Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Train 5 models on your balanced RTK dataset and save all artifacts\n",
        "# =========================================================\n",
        "!pip -q install torch torchvision torchaudio --upgrade\n",
        "!pip -q install pandas scikit-learn matplotlib\n",
        "\n",
        "import os, time, json, math, copy, random\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "DATA_ROOT = Path(\"/content/prepared_dataset_balanced\")  # from your balancing step\n",
        "assert (DATA_ROOT/\"train\").exists(), \"Balanced dataset not found at /content/prepared_dataset_balanced\"\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "RUN_MODELS = [\"CNN\", \"RESNET18\", \"MOBILENETV2\", \"VGG16\", \"INCEPTIONV3\"]  # change to subset if needed\n",
        "\n",
        "SAVE_DIR = Path(SAVE_DIR)  # from your earlier cell\n",
        "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Using device:\", DEVICE)\n",
        "print(\"Saving to:\", SAVE_DIR)\n",
        "\n",
        "# ---------------- Transforms ----------------\n",
        "train_tf_224 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "val_tf_224 = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "train_tf_299 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "])\n",
        "val_tf_299 = transforms.Compose([\n",
        "    transforms.Resize(342), transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "])\n",
        "\n",
        "def make_dataloaders(root: Path, image_size: int):\n",
        "    tr_tf, va_tf = (train_tf_224, val_tf_224) if image_size==224 else (train_tf_299, val_tf_299)\n",
        "    train_ds = datasets.ImageFolder(root/\"train\", transform=tr_tf)\n",
        "    val_ds   = datasets.ImageFolder(root/\"val\",   transform=va_tf)\n",
        "    test_ds  = datasets.ImageFolder(root/\"test\",  transform=va_tf) if (root/\"test\").exists() else None\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True) if test_ds else None\n",
        "    return train_loader, val_loader, test_loader, train_ds.classes\n",
        "\n",
        "# ---------------- Models ----------------\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
        "            nn.Linear(128, 128), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "def build_model(name: str, num_classes: int):\n",
        "    n = name.upper()\n",
        "    if n == \"CNN\":\n",
        "        m = SmallCNN(num_classes); img=224\n",
        "    elif n == \"RESNET18\":\n",
        "        m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes); img=224\n",
        "    elif n == \"MOBILENETV2\":\n",
        "        m = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
        "        m.classifier[-1] = nn.Linear(m.classifier[-1].in_features, num_classes); img=224\n",
        "    elif n == \"VGG16\":\n",
        "        m = models.vgg16_bn(weights=models.VGG16_BN_Weights.DEFAULT)\n",
        "        m.classifier[-1] = nn.Linear(m.classifier[-1].in_features, num_classes); img=224\n",
        "    elif n == \"INCEPTIONV3\":\n",
        "        m = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT, aux_logits=True)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "        if m.aux_logits:\n",
        "            m.AuxLogits.fc = nn.Linear(m.AuxLogits.fc.in_features, num_classes)\n",
        "        img=299\n",
        "    else:\n",
        "        raise ValueError(name)\n",
        "    params = sum(p.numel() for p in m.parameters())\n",
        "    return m, img, params\n",
        "\n",
        "# ---------------- Train/Eval helpers ----------------\n",
        "def train_one_epoch(model, loader, criterion, optimizer, scaler=None, use_inception=False):\n",
        "    model.train()\n",
        "    tl, tc, tn = 0.0, 0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                out = model(x)\n",
        "                if use_inception and isinstance(out, tuple):\n",
        "                    logits, aux = out\n",
        "                    loss = criterion(logits, y) + 0.4*criterion(aux, y)\n",
        "                else:\n",
        "                    logits = out\n",
        "                    loss = criterion(logits, y)\n",
        "            scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        else:\n",
        "            out = model(x)\n",
        "            if use_inception and isinstance(out, tuple):\n",
        "                logits, aux = out; loss = criterion(logits, y) + 0.4*criterion(aux, y)\n",
        "            else:\n",
        "                logits = out; loss = criterion(logits, y)\n",
        "            loss.backward(); optimizer.step()\n",
        "        tl += loss.item()*x.size(0)\n",
        "        pred = logits.argmax(1); tn += x.size(0); tc += (pred==y).sum().item()\n",
        "    return tl/tn, tc/tn\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    tl, tc, tn = 0.0, 0, 0\n",
        "    y_all, p_all = [], []\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "        out = model(x)\n",
        "        if isinstance(out, tuple): out = out[0]\n",
        "        loss = criterion(out, y)\n",
        "        tl += loss.item()*x.size(0)\n",
        "        p = out.argmax(1)\n",
        "        tn += x.size(0); tc += (p==y).sum().item()\n",
        "        y_all.append(y.detach().cpu().numpy()); p_all.append(p.detach().cpu().numpy())\n",
        "    y_all = np.concatenate(y_all) if y_all else np.array([])\n",
        "    p_all = np.concatenate(p_all) if p_all else np.array([])\n",
        "    return tl/tn, tc/tn, y_all, p_all\n",
        "\n",
        "@torch.no_grad()\n",
        "def measure_inference_time(model, image_size=224, repeats=30):\n",
        "    model.eval()\n",
        "    dummy = torch.randn(1,3,image_size,image_size, device=DEVICE)\n",
        "    for _ in range(5): _ = model(dummy)\n",
        "    if DEVICE.type == \"cuda\": torch.cuda.synchronize()\n",
        "    t0 = time.time()\n",
        "    for _ in range(repeats): _ = model(dummy)\n",
        "    if DEVICE.type == \"cuda\": torch.cuda.synchronize()\n",
        "    return (time.time()-t0)*1000.0/repeats\n",
        "\n",
        "def plot_confusion(cm, classes, out_png):\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.xticks(range(len(classes)), classes, rotation=45, ha=\"right\")\n",
        "    plt.yticks(range(len(classes)), classes)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, str(cm[i,j]), ha=\"center\", va=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_png, dpi=140); plt.close()\n",
        "\n",
        "def plot_curves(history, out_png):\n",
        "    ep = range(1, len(history[\"train_acc\"])+1)\n",
        "    plt.figure(figsize=(7,5))\n",
        "    plt.plot(ep, history[\"train_acc\"], label=\"train_acc\")\n",
        "    plt.plot(ep, history[\"val_acc\"],   label=\"val_acc\")\n",
        "    plt.plot(ep, history[\"train_loss\"], label=\"train_loss\")\n",
        "    plt.plot(ep, history[\"val_loss\"],   label=\"val_loss\")\n",
        "    plt.legend(); plt.xlabel(\"epoch\"); plt.ylabel(\"value\"); plt.title(\"Learning Curves\")\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=140); plt.close()\n",
        "\n",
        "# ---------------- Run all models ----------------\n",
        "results = []\n",
        "all_class_names = sorted(os.listdir(DATA_ROOT/\"train\"))\n",
        "print(\"Classes:\", all_class_names)\n",
        "\n",
        "for model_name in RUN_MODELS:\n",
        "    print(\"\\n\"+\"=\"*72)\n",
        "    print(f\"Training: {model_name}\")\n",
        "    # Make loaders first (we need correct image size per arch)\n",
        "    dummy, img_size, _ = build_model(model_name, num_classes=len(all_class_names))\n",
        "    train_loader, val_loader, test_loader, class_names = make_dataloaders(DATA_ROOT, img_size)\n",
        "    assert class_names == all_class_names, \"Class order mismatch between splits.\"\n",
        "\n",
        "    # Build model\n",
        "    model, img_size, n_params = build_model(model_name, num_classes=len(class_names))\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2, verbose=True)\n",
        "    scaler = torch.cuda.amp.GradScaler() if DEVICE.type==\"cuda\" else None\n",
        "    use_inception = (model_name.upper()==\"INCEPTIONV3\")\n",
        "\n",
        "    history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[]}\n",
        "    best_va, best_state = 0.0, None\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, criterion, optimizer, scaler, use_inception)\n",
        "        va_loss, va_acc, _, _ = evaluate(model, val_loader, criterion)\n",
        "        scheduler.step(va_acc)\n",
        "        history[\"train_loss\"].append(tr_loss); history[\"train_acc\"].append(tr_acc)\n",
        "        history[\"val_loss\"].append(va_loss);   history[\"val_acc\"].append(va_acc)\n",
        "        print(f\"[{model_name}] Ep {ep:02d}/{EPOCHS} | Train {tr_acc:.4f}/{tr_loss:.4f} | Val {va_acc:.4f}/{va_loss:.4f}\")\n",
        "        if va_acc > best_va:\n",
        "            best_va = va_acc; best_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    # Save artifacts\n",
        "    out_dir = SAVE_DIR / model_name\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    torch.save({\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"classes\": class_names,\n",
        "        \"image_size\": img_size,\n",
        "        \"best_val_acc\": float(best_va)\n",
        "    }, out_dir / f\"{model_name}_best.pth\")\n",
        "    with open(out_dir / \"classes.json\", \"w\") as f:\n",
        "        json.dump(class_names, f, indent=2)\n",
        "    plot_curves(history, out_dir / \"learning_curves.png\")\n",
        "\n",
        "    # Validation CM + report\n",
        "    _, _, y_true, y_pred = evaluate(model, val_loader, criterion)\n",
        "    if y_true.size and y_pred.size:\n",
        "        cm_val = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
        "        np.savetxt(out_dir / \"confusion_val.csv\", cm_val, fmt=\"%d\", delimiter=\",\")\n",
        "        with open(out_dir / \"classification_report_val.txt\",\"w\") as f:\n",
        "            f.write(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n",
        "        plot_confusion(cm_val, class_names, out_dir / \"confusion_val.png\")\n",
        "\n",
        "    # Optional test\n",
        "    test_acc = None\n",
        "    if test_loader is not None:\n",
        "        _, test_acc, y_t, y_p = evaluate(model, test_loader, criterion)\n",
        "        if y_t.size and y_p.size:\n",
        "            cm_test = confusion_matrix(y_t, y_p, labels=list(range(len(class_names))))\n",
        "            np.savetxt(out_dir / \"confusion_test.csv\", cm_test, fmt=\"%d\", delimiter=\",\")\n",
        "            plot_confusion(cm_test, class_names, out_dir / \"confusion_test.png\")\n",
        "        print(f\"[{model_name}] Test Acc:\", None if test_acc is None else f\"{test_acc:.4f}\")\n",
        "\n",
        "    # Inference speed\n",
        "    inf_ms = measure_inference_time(model, image_size=img_size, repeats=30)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Params (M)\": round(n_params/1e6, 2),\n",
        "        \"Val Acc\": round(float(best_va), 4),\n",
        "        \"Test Acc\": round(float(test_acc), 4) if test_acc is not None else None,\n",
        "        \"Image Size\": img_size,\n",
        "        \"Per-Image Inference (ms)\": round(float(inf_ms), 2),\n",
        "        \"Checkpoint\": str(out_dir / f\"{model_name}_best.pth\")\n",
        "    })\n",
        "\n",
        "# ---------------- Summary table ----------------\n",
        "df = pd.DataFrame(results).sort_values(by=\"Val Acc\", ascending=False)\n",
        "display(df)\n",
        "df_path = SAVE_DIR / \"comparison_results.csv\"\n",
        "df.to_csv(df_path, index=False)\n",
        "print(\"âœ… Saved comparison table to:\", df_path)\n",
        "print(\"âœ… Per-model artifacts saved under:\", SAVE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "QiXIoty8y36W",
        "outputId": "e88cad1a-4148-478d-e86d-3436696ea6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Saving to: /content/drive/MyDrive/model_comparison\n",
            "Classes: ['asphalt_bad', 'asphalt_good', 'asphalt_regular', 'paved_bad', 'paved_regular', 'unpaved_bad', 'unpaved_regular']\n",
            "\n",
            "========================================================================\n",
            "Training: CNN\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1727165620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0muse_inception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"INCEPTIONV3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
          ]
        }
      ]
    }
  ]
}